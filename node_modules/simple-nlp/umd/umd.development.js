(function webpackUniversalModuleDefinition(root, factory) {
	if(typeof exports === 'object' && typeof module === 'object')
		module.exports = factory();
	else if(typeof define === 'function' && define.amd)
		define("umd.development", [], factory);
	else if(typeof exports === 'object')
		exports["umd.development"] = factory();
	else
		root["umd.development"] = factory();
})(window, function() {
return /******/ (function(modules) { // webpackBootstrap
/******/ 	// The module cache
/******/ 	var installedModules = {};
/******/
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/
/******/ 		// Check if module is in cache
/******/ 		if(installedModules[moduleId]) {
/******/ 			return installedModules[moduleId].exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = installedModules[moduleId] = {
/******/ 			i: moduleId,
/******/ 			l: false,
/******/ 			exports: {}
/******/ 		};
/******/
/******/ 		// Execute the module function
/******/ 		modules[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/
/******/ 		// Flag the module as loaded
/******/ 		module.l = true;
/******/
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/
/******/
/******/ 	// expose the modules object (__webpack_modules__)
/******/ 	__webpack_require__.m = modules;
/******/
/******/ 	// expose the module cache
/******/ 	__webpack_require__.c = installedModules;
/******/
/******/ 	// define getter function for harmony exports
/******/ 	__webpack_require__.d = function(exports, name, getter) {
/******/ 		if(!__webpack_require__.o(exports, name)) {
/******/ 			Object.defineProperty(exports, name, { enumerable: true, get: getter });
/******/ 		}
/******/ 	};
/******/
/******/ 	// define __esModule on exports
/******/ 	__webpack_require__.r = function(exports) {
/******/ 		if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 			Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 		}
/******/ 		Object.defineProperty(exports, '__esModule', { value: true });
/******/ 	};
/******/
/******/ 	// create a fake namespace object
/******/ 	// mode & 1: value is a module id, require it
/******/ 	// mode & 2: merge all properties of value into the ns
/******/ 	// mode & 4: return value when already ns object
/******/ 	// mode & 8|1: behave like require
/******/ 	__webpack_require__.t = function(value, mode) {
/******/ 		if(mode & 1) value = __webpack_require__(value);
/******/ 		if(mode & 8) return value;
/******/ 		if((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;
/******/ 		var ns = Object.create(null);
/******/ 		__webpack_require__.r(ns);
/******/ 		Object.defineProperty(ns, 'default', { enumerable: true, value: value });
/******/ 		if(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));
/******/ 		return ns;
/******/ 	};
/******/
/******/ 	// getDefaultExport function for compatibility with non-harmony modules
/******/ 	__webpack_require__.n = function(module) {
/******/ 		var getter = module && module.__esModule ?
/******/ 			function getDefault() { return module['default']; } :
/******/ 			function getModuleExports() { return module; };
/******/ 		__webpack_require__.d(getter, 'a', getter);
/******/ 		return getter;
/******/ 	};
/******/
/******/ 	// Object.prototype.hasOwnProperty.call
/******/ 	__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };
/******/
/******/ 	// __webpack_public_path__
/******/ 	__webpack_require__.p = "";
/******/
/******/
/******/ 	// Load entry module and return exports
/******/ 	return __webpack_require__(__webpack_require__.s = 2);
/******/ })
/************************************************************************/
/******/ ([
/* 0 */
/***/ (function(module, exports, __webpack_require__) {

"use strict";

Object.defineProperty(exports, "__esModule", { value: true });
exports.stemmer = function (tokens, stemmerFn) {
    return tokens.map(function (t) { return stemmerFn(t); });
};


/***/ }),
/* 1 */
/***/ (function(module, exports, __webpack_require__) {

"use strict";

function __export(m) {
    for (var p in m) if (!exports.hasOwnProperty(p)) exports[p] = m[p];
}
Object.defineProperty(exports, "__esModule", { value: true });
__export(__webpack_require__(9));
__export(__webpack_require__(0));


/***/ }),
/* 2 */
/***/ (function(module, exports, __webpack_require__) {

"use strict";

function __export(m) {
    for (var p in m) if (!exports.hasOwnProperty(p)) exports[p] = m[p];
}
Object.defineProperty(exports, "__esModule", { value: true });
__export(__webpack_require__(3));


/***/ }),
/* 3 */
/***/ (function(module, exports, __webpack_require__) {

"use strict";

function __export(m) {
    for (var p in m) if (!exports.hasOwnProperty(p)) exports[p] = m[p];
}
Object.defineProperty(exports, "__esModule", { value: true });
__export(__webpack_require__(4));
__export(__webpack_require__(7));
__export(__webpack_require__(11));


/***/ }),
/* 4 */
/***/ (function(module, exports, __webpack_require__) {

"use strict";

function __export(m) {
    for (var p in m) if (!exports.hasOwnProperty(p)) exports[p] = m[p];
}
Object.defineProperty(exports, "__esModule", { value: true });
__export(__webpack_require__(5));
__export(__webpack_require__(6));


/***/ }),
/* 5 */
/***/ (function(module, exports, __webpack_require__) {

"use strict";

Object.defineProperty(exports, "__esModule", { value: true });
var stemmerHelpers_1 = __webpack_require__(0);
// denote groups of consecutive consonants with a C and consecutive vowels
// with a V.
function categorizeGroups(token) {
    return token
        .replace(/[^aeiouy]+y/g, "CV")
        .replace(/[aeiou]+/g, "V")
        .replace(/[^V]+/g, "C");
}
// denote single consonants with a C and single vowels with a V
function categorizeChars(token) {
    return token
        .replace(/[^aeiouy]y/g, "CV")
        .replace(/[aeiou]/g, "V")
        .replace(/[^V]/g, "C");
}
// calculate the "measure" M of a word. M is the count of VC sequences dropping
// an initial C if it exists and a trailing V if it exists.
function measure(token) {
    if (!token)
        return -1;
    return (categorizeGroups(token)
        .replace(/^C/, "")
        .replace(/V$/, "").length / 2);
}
// determine if a token end with a double consonant i.e. happ
function endsWithDoublCons(token) {
    return token.match(/([^aeiou])\1$/);
}
// replace a pattern in a word. if a replacement occurs an optional callback
// can be called to post-process the result. if no match is made NULL is
// returned.
function attemptReplace(token, pattern, replacement, callback) {
    var result = null;
    if (typeof pattern == "string" && token.substr(0 - pattern.length) == pattern)
        result = token.replace(new RegExp(pattern + "$"), replacement);
    else if (pattern instanceof RegExp && token.match(pattern))
        result = token.replace(pattern, replacement);
    if (result && callback)
        return callback(result);
    else
        return result;
}
// attempt to replace a list of patterns/replacements on a token for a minimum
// measure M.
function attemptReplacePatterns(token, replacements, measureThreshold) {
    var replacement = token;
    for (var i = 0; i < replacements.length; i++) {
        if (measureThreshold === null ||
            (measureThreshold &&
                measure(attemptReplace(token, replacements[i][0], replacements[i][1])) >
                    measureThreshold)) {
            replacement =
                attemptReplace(replacement, replacements[i][0], replacements[i][2]) ||
                    replacement;
        }
    }
    return replacement;
}
// replace a list of patterns/replacements on a word. if no match is made return
// the original token.
function replacePatterns(token, replacements, measureThreshold) {
    return attemptReplacePatterns(token, replacements, measureThreshold) || token;
}
// TODO: this should replace all of the messy replacement stuff above
function replaceRegex(token, regex, includeParts, minimumMeasure) {
    var result = "";
    if (regex.test(token)) {
        var parts_1 = regex.exec(token);
        if (parts_1 !== null) {
            includeParts.forEach(function (i) {
                result += parts_1[i];
            });
        }
    }
    if (measure(result) > minimumMeasure) {
        return result;
    }
    return null;
}
// step 1a as defined for the porter stemmer algorithm.
function step1a(token) {
    if (token.match(/(ss|i)es$/)) {
        return token.replace(/(ss|i)es$/, "$1");
    }
    if (token.substr(-1) == "s" &&
        token.substr(-2, 1) != "s" &&
        token.length > 2) {
        return token.replace(/s?$/, "");
    }
    return token;
}
// step 1b as defined for the porter stemmer algorithm.
function step1b(token) {
    if (token.substr(-3) == "eed") {
        if (measure(token.substr(0, token.length - 3)) > 0)
            return token.replace(/eed$/, "ee");
    }
    else {
        var result_1 = attemptReplace(token, /(ed|ing)$/, "", function (token) {
            if (categorizeGroups(token).indexOf("V") >= 0) {
                result_1 = attemptReplacePatterns(token, [
                    ["at", "", "ate"],
                    ["bl", "", "ble"],
                    ["iz", "", "ize"]
                ]);
                if (result_1 != token) {
                    return result_1;
                }
                else {
                    if (endsWithDoublCons(token) && token.match(/[^lsz]$/)) {
                        return token.replace(/([^aeiou])\1$/, "$1");
                    }
                    if (measure(token) == 1 &&
                        categorizeChars(token).substr(-3) == "CVC" &&
                        token.match(/[^wxy]$/)) {
                        return token + "e";
                    }
                }
                return token;
            }
            return null;
        });
        if (result_1) {
            return result_1;
        }
    }
    return token;
}
// step 1c as defined for the porter stemmer algorithm.
function step1c(token) {
    var categorizedGroups = categorizeGroups(token);
    if (token.substr(-1) == "y" &&
        categorizedGroups.substr(0, categorizedGroups.length - 1).indexOf("V") > -1) {
        return token.replace(/y$/, "i");
    }
    return token;
}
// step 2 as defined for the porter stemmer algorithm.
function step2(token) {
    token = replacePatterns(token, [
        ["ational", "", "ate"],
        ["tional", "", "tion"],
        ["enci", "", "ence"],
        ["anci", "", "ance"],
        ["izer", "", "ize"],
        ["abli", "", "able"],
        ["bli", "", "ble"],
        ["alli", "", "al"],
        ["entli", "", "ent"],
        ["eli", "", "e"],
        ["ousli", "", "ous"],
        ["ization", "", "ize"],
        ["ation", "", "ate"],
        ["ator", "", "ate"],
        ["alism", "", "al"],
        ["iveness", "", "ive"],
        ["fulness", "", "ful"],
        ["ousness", "", "ous"],
        ["aliti", "", "al"],
        ["iviti", "", "ive"],
        ["biliti", "", "ble"],
        ["logi", "", "log"]
    ], 0);
    return token;
}
// step 3 as defined for the porter stemmer algorithm.
function step3(token) {
    return replacePatterns(token, [
        ["icate", "", "ic"],
        ["ative", "", ""],
        ["alize", "", "al"],
        ["iciti", "", "ic"],
        ["ical", "", "ic"],
        ["ful", "", ""],
        ["ness", "", ""]
    ], 0);
}
// step 4 as defined for the porter stemmer algorithm.
function step4(token) {
    return (replaceRegex(token, /^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/, [1], 1) ||
        replaceRegex(token, /^(.+?)(s|t)(ion)$/, [1, 2], 1) ||
        token);
}
// step 5a as defined for the porter stemmer algorithm.
function step5a(token) {
    var m = measure(token.replace(/e$/, ""));
    if (m > 1 ||
        (m == 1 &&
            !(categorizeChars(token).substr(-4, 3) == "CVC" && token.match(/[^wxy].$/)))) {
        token = token.replace(/e$/, "");
    }
    return token;
}
// step 5b as defined for the porter stemmer algorithm.
function step5b(token) {
    if (measure(token) > 1) {
        return token.replace(/ll$/, "l");
    }
    return token;
}
// perform full stemming algorithm on a single word
var porterStemFn = function (token) {
    if (token.length < 3)
        return token;
    return step5b(step5a(step4(step3(step2(step1c(step1b(step1a(token.toLowerCase())))))))).toString();
};
exports.porterStemmer = function (text) { return stemmerHelpers_1.stemmer(text, porterStemFn); };


/***/ }),
/* 6 */
/***/ (function(module, exports, __webpack_require__) {

"use strict";

Object.defineProperty(exports, "__esModule", { value: true });
var stemmerHelpers_1 = __webpack_require__(0);
exports.porterStemmerFr = function (text) {
    return stemmerHelpers_1.stemmer(text, porterStemFrFn);
};
/**
 * Stem a word thanks to Porter Stemmer rules
 * @param  {String} token Word to be stemmed
 * @return {String}       Stemmed word
 */
function porterStemFrFn(token) {
    token = prelude(token.toLowerCase());
    if (token.length == 1)
        return token;
    var regs = regions(token);
    var r1_txt, r2_txt, rv_txt;
    r1_txt = token.substring(regs.r1);
    r2_txt = token.substring(regs.r2);
    rv_txt = token.substring(regs.rv);
    // Step 1
    var beforeStep1 = token;
    var suf, pref2, pref3, letterBefore, letter2Before, i;
    var doStep2a = false;
    if ((suf = endsinArr(r2_txt, [
        "ance",
        "iqUe",
        "isme",
        "able",
        "iste",
        "eux",
        "ances",
        "iqUes",
        "ismes",
        "ables",
        "istes"
    ])) != "") {
        token = token.slice(0, -suf.length); // delete
    }
    else if ((suf = endsinArr(token, [
        "icatrice",
        "icateur",
        "ication",
        "icatrices",
        "icateurs",
        "ications"
    ])) != "") {
        if (endsinArr(r2_txt, [
            "icatrice",
            "icateur",
            "ication",
            "icatrices",
            "icateurs",
            "ications"
        ]) != "") {
            token = token.slice(0, -suf.length); // delete
        }
        else {
            token = token.slice(0, -suf.length) + "iqU"; // replace by iqU
        }
    }
    else if ((suf = endsinArr(r2_txt, [
        "atrice",
        "ateur",
        "ation",
        "atrices",
        "ateurs",
        "ations"
    ])) != "") {
        token = token.slice(0, -suf.length); // delete
    }
    else if ((suf = endsinArr(r2_txt, ["logie", "logies"])) != "") {
        token = token.slice(0, -suf.length) + "log"; // replace with log
    }
    else if ((suf = endsinArr(r2_txt, ["usion", "ution", "usions", "utions"])) != "") {
        token = token.slice(0, -suf.length) + "u"; // replace with u
    }
    else if ((suf = endsinArr(r2_txt, ["ence", "ences"])) != "") {
        token = token.slice(0, -suf.length) + "ent"; // replace with ent
    }
    // ement(s)
    else if ((suf = endsinArr(r1_txt, ["issement", "issements"])) != "") {
        if (!isVowel(token[token.length - suf.length - 1])) {
            token = token.slice(0, -suf.length); // delete
            r1_txt = token.substring(regs.r1);
            r2_txt = token.substring(regs.r2);
            rv_txt = token.substring(regs.rv);
        }
    }
    else if ((suf = endsinArr(r2_txt, ["ativement", "ativements"])) != "") {
        token = token.slice(0, -suf.length); // delete
    }
    else if ((suf = endsinArr(r2_txt, ["ivement", "ivements"])) != "") {
        token = token.slice(0, -suf.length); // delete
    }
    else if ((suf = endsinArr(token, ["eusement", "eusements"])) != "") {
        if ((suf = endsinArr(r2_txt, ["eusement", "eusements"])) != "")
            token = token.slice(0, -suf.length);
        // delete
        else if ((suf = endsinArr(r1_txt, ["eusement", "eusements"])) != "")
            token = token.slice(0, -suf.length) + "eux";
        // replace by eux
        else if ((suf = endsinArr(rv_txt, ["ement", "ements"])) != "")
            token = token.slice(0, -suf.length); // delete
    }
    else if ((suf = endsinArr(r2_txt, [
        "ablement",
        "ablements",
        "iqUement",
        "iqUements"
    ])) != "") {
        token = token.slice(0, -suf.length); // delete
    }
    else if ((suf = endsinArr(rv_txt, [
        "ièrement",
        "ièrements",
        "Ièrement",
        "Ièrements"
    ])) != "") {
        token = token.slice(0, -suf.length) + "i"; // replace by i
    }
    else if ((suf = endsinArr(rv_txt, ["ement", "ements"])) != "") {
        token = token.slice(0, -suf.length); // delete
    }
    // ité(s)
    else if ((suf = endsinArr(token, ["icité", "icités"])) != "") {
        if (endsinArr(r2_txt, ["icité", "icités"]) != "")
            token = token.slice(0, -suf.length);
        // delete
        else
            token = token.slice(0, -suf.length) + "iqU"; // replace by iqU
    }
    else if ((suf = endsinArr(token, ["abilité", "abilités"])) != "") {
        if (endsinArr(r2_txt, ["abilité", "abilités"]) != "")
            token = token.slice(0, -suf.length);
        // delete
        else
            token = token.slice(0, -suf.length) + "abl"; // replace by abl
    }
    else if ((suf = endsinArr(r2_txt, ["ité", "ités"])) != "") {
        token = token.slice(0, -suf.length); // delete if in R2
    }
    else if ((suf = endsinArr(token, ["icatif", "icative", "icatifs", "icatives"])) != "") {
        if ((suf = endsinArr(r2_txt, ["icatif", "icative", "icatifs", "icatives"])) !=
            "") {
            token = token.slice(0, -suf.length); // delete
            r2_txt = token.substring(regs.r2);
            rv_txt = token.substring(regs.rv);
        }
        if ((suf = endsinArr(r2_txt, ["atif", "ative", "atifs", "atives"])) != "") {
            token = token.slice(0, -suf.length - 2) + "iqU"; // replace with iqU
            r2_txt = token.substring(regs.r2);
            rv_txt = token.substring(regs.rv);
        }
    }
    else if ((suf = endsinArr(r2_txt, ["atif", "ative", "atifs", "atives"])) != "") {
        token = token.slice(0, -suf.length); // delete
    }
    else if ((suf = endsinArr(r2_txt, ["if", "ive", "ifs", "ives"])) != "") {
        token = token.slice(0, -suf.length); // delete
    }
    else if ((suf = endsinArr(token, ["eaux"])) != "") {
        token = token.slice(0, -suf.length) + "eau"; // replace by eau
    }
    else if ((suf = endsinArr(r1_txt, ["aux"])) != "") {
        token = token.slice(0, -suf.length) + "al"; // replace by al
    }
    else if ((suf = endsinArr(r2_txt, ["euse", "euses"])) != "") {
        token = token.slice(0, -suf.length); // delete
    }
    else if ((suf = endsinArr(r1_txt, ["euse", "euses"])) != "") {
        token = token.slice(0, -suf.length) + "eux"; // replace by eux
    }
    else if ((suf = endsinArr(rv_txt, ["amment"])) != "") {
        token = token.slice(0, -suf.length) + "ant"; // replace by ant
        doStep2a = true;
    }
    else if ((suf = endsinArr(rv_txt, ["emment"])) != "") {
        token = token.slice(0, -suf.length) + "ent"; // replace by ent
        doStep2a = true;
    }
    else if ((suf = endsinArr(rv_txt, ["ment", "ments"])) != "") {
        // letter before must be a vowel in RV
        letterBefore = token[token.length - suf.length - 1];
        if (isVowel(letterBefore) && endsin(rv_txt, letterBefore + suf)) {
            token = token.slice(0, -suf.length); // delete
            doStep2a = true;
        }
    }
    // re compute regions
    r1_txt = token.substring(regs.r1);
    r2_txt = token.substring(regs.r2);
    rv_txt = token.substring(regs.rv);
    // Step 2a
    var beforeStep2a = token;
    var step2aDone = false;
    if (beforeStep1 === token || doStep2a) {
        step2aDone = true;
        if ((suf = endsinArr(rv_txt, [
            "îmes",
            "ît",
            "îtes",
            "i",
            "ie",
            "Ie",
            "ies",
            "ir",
            "ira",
            "irai",
            "iraIent",
            "irais",
            "irait",
            "iras",
            "irent",
            "irez",
            "iriez",
            "irions",
            "irons",
            "iront",
            "is",
            "issaIent",
            "issais",
            "issait",
            "issant",
            "issante",
            "issantes",
            "issants",
            "isse",
            "issent",
            "isses",
            "issez",
            "issiez",
            "issions",
            "issons",
            "it"
        ])) != "") {
            letterBefore = token[token.length - suf.length - 1];
            if (!isVowel(letterBefore) && endsin(rv_txt, letterBefore + suf))
                token = token.slice(0, -suf.length); // delete
        }
    }
    // Step 2b
    if (step2aDone && token === beforeStep2a) {
        if ((suf = endsinArr(rv_txt, [
            "é",
            "ée",
            "ées",
            "és",
            "èrent",
            "er",
            "era",
            "erai",
            "eraIent",
            "erais",
            "erait",
            "eras",
            "erez",
            "eriez",
            "erions",
            "erons",
            "eront",
            "ez",
            "iez",
            "Iez"
        ])) != "") {
            token = token.slice(0, -suf.length); // delete
            r2_txt = token.substring(regs.r2);
            rv_txt = token.substring(regs.rv);
        }
        else if ((suf = endsinArr(rv_txt, ["ions"])) != "" &&
            endsinArr(r2_txt, ["ions"])) {
            token = token.slice(0, -suf.length); // delete
            r2_txt = token.substring(regs.r2);
            rv_txt = token.substring(regs.rv);
        }
        // add 'Ie' suffix to pass test for 'évanouie'
        else if ((suf = endsinArr(rv_txt, [
            "âmes",
            "ât",
            "âtes",
            "a",
            "ai",
            "aIent",
            "ais",
            "ait",
            "ant",
            "ante",
            "antes",
            "ants",
            "as",
            "asse",
            "assent",
            "asses",
            "assiez",
            "assions"
        ])) != "") {
            token = token.slice(0, -suf.length); // delete
            letterBefore = token[token.length - 1];
            if (letterBefore === "e" && endsin(rv_txt, "e" + suf))
                token = token.slice(0, -1);
            r2_txt = token.substring(regs.r2);
            rv_txt = token.substring(regs.rv);
        }
    }
    // Step 3
    if (!(token === beforeStep1)) {
        if (token[token.length - 1] === "Y")
            token = token.slice(0, -1) + "i";
        if (token[token.length - 1] === "ç")
            token = token.slice(0, -1) + "c";
    } // Step 4
    else {
        letterBefore = token[token.length - 1];
        letter2Before = token[token.length - 2];
        if (letterBefore === "s" &&
            ["a", "i", "o", "u", "è", "s"].indexOf(letter2Before) == -1) {
            token = token.slice(0, -1);
            r1_txt = token.substring(regs.r1);
            r2_txt = token.substring(regs.r2);
            rv_txt = token.substring(regs.rv);
        }
        if ((suf = endsinArr(r2_txt, ["ion"])) != "") {
            letterBefore = token[token.length - suf.length - 1];
            if (letterBefore === "s" || letterBefore === "t") {
                token = token.slice(0, -suf.length); // delete
                r1_txt = token.substring(regs.r1);
                r2_txt = token.substring(regs.r2);
                rv_txt = token.substring(regs.rv);
            }
        }
        if ((suf = endsinArr(rv_txt, ["ier", "ière", "Ier", "Ière"])) != "") {
            token = token.slice(0, -suf.length) + "i"; // replace by i
            r1_txt = token.substring(regs.r1);
            r2_txt = token.substring(regs.r2);
            rv_txt = token.substring(regs.rv);
        }
        if ((suf = endsinArr(rv_txt, "e")) != "") {
            token = token.slice(0, -suf.length); // delete
            r1_txt = token.substring(regs.r1);
            r2_txt = token.substring(regs.r2);
            rv_txt = token.substring(regs.rv);
        }
        if ((suf = endsinArr(rv_txt, "ë")) != "") {
            if (token.slice(token.length - 3, -1) === "gu")
                token = token.slice(0, -suf.length); // delete
        }
    }
    // Step 5
    if ((suf = endsinArr(token, ["enn", "onn", "ett", "ell", "eill"])) != "") {
        token = token.slice(0, -1); // delete last letter
    }
    // Step 6
    i = token.length - 1;
    while (i > 0) {
        if (!isVowel(token[i])) {
            i--;
        }
        else if (i !== token.length - 1 &&
            (token[i] === "é" || token[i] === "è")) {
            token =
                token.substring(0, i) + "e" + token.substring(i + 1, token.length);
            break;
        }
        else {
            break;
        }
    }
    return token.toLowerCase();
}
/**
 * Compute r1, r2, rv regions as required by french porter stemmer algorithm
 * @param  {String} token Word to compute regions on
 * @return {Object}       Regions r1, r2, rv as offsets from the begining of the word
 */
function regions(token) {
    var r1, r2, rv, len;
    var i;
    r1 = r2 = rv = len = token.length;
    // R1 is the region after the first non-vowel following a vowel,
    for (var i_1 = 0; i_1 < len - 1 && r1 == len; i_1++) {
        if (isVowel(token[i_1]) && !isVowel(token[i_1 + 1])) {
            r1 = i_1 + 2;
        }
    }
    // Or is the null region at the end of the word if there is no such non-vowel.
    // R2 is the region after the first non-vowel following a vowel in R1
    for (i = r1; i < len - 1 && r2 == len; i++) {
        if (isVowel(token[i]) && !isVowel(token[i + 1])) {
            r2 = i + 2;
        }
    }
    // Or is the null region at the end of the word if there is no such non-vowel.
    // RV region
    var three = token.slice(0, 3);
    if (isVowel(token[0]) && isVowel(token[1])) {
        rv = 3;
    }
    if (three === "par" || three == "col" || three === "tap")
        rv = 3;
    // the region after the first vowel not at the beginning of the word or null
    else {
        for (i = 1; i < len - 1 && rv == len; i++) {
            if (isVowel(token[i])) {
                rv = i + 1;
            }
        }
    }
    return {
        r1: r1,
        r2: r2,
        rv: rv
    };
}
/**
 * Pre-process/prepare words as required by french porter stemmer algorithm
 * @param  {String} token Word to be prepared
 * @return {String}       Prepared word
 */
function prelude(token) {
    token = token.toLowerCase();
    var result = "";
    var i = 0;
    // special case for i = 0 to avoid '-1' index
    if (token[i] === "y" && isVowel(token[i + 1])) {
        result += token[i].toUpperCase();
    }
    else {
        result += token[i];
    }
    for (i = 1; i < token.length; i++) {
        if ((token[i] === "u" || token[i] === "i") &&
            isVowel(token[i - 1]) &&
            isVowel(token[i + 1])) {
            result += token[i].toUpperCase();
        }
        else if (token[i] === "y" &&
            (isVowel(token[i - 1]) || isVowel(token[i + 1]))) {
            result += token[i].toUpperCase();
        }
        else if (token[i] === "u" && token[i - 1] === "q") {
            result += token[i].toUpperCase();
        }
        else {
            result += token[i];
        }
    }
    return result;
}
/**
 * Return longest matching suffixes for a token or '' if no suffix match
 * @param  {String} token    Word to find matching suffix
 * @param  {Array} suffixes  Array of suffixes to test matching
 * @return {String}          Longest found matching suffix or ''
 */
function endsinArr(token, suffixes) {
    var i, longest = "";
    for (i = 0; i < suffixes.length; i++) {
        if (endsin(token, suffixes[i]) && suffixes[i].length > longest.length)
            longest = suffixes[i];
    }
    return longest;
}
// TODO: Let this be an array and do vowelArray.includes(letter)
function isVowel(letter) {
    return (letter == "a" ||
        letter == "e" ||
        letter == "i" ||
        letter == "o" ||
        letter == "u" ||
        letter == "y" ||
        letter == "â" ||
        letter == "à" ||
        letter == "ë" ||
        letter == "é" ||
        letter == "ê" ||
        letter == "è" ||
        letter == "ï" ||
        letter == "î" ||
        letter == "ô" ||
        letter == "û" ||
        letter == "ù");
}
function endsin(token, suffix) {
    if (token.length < suffix.length)
        return false;
    return token.slice(-suffix.length) == suffix;
}


/***/ }),
/* 7 */
/***/ (function(module, exports, __webpack_require__) {

"use strict";

function __export(m) {
    for (var p in m) if (!exports.hasOwnProperty(p)) exports[p] = m[p];
}
Object.defineProperty(exports, "__esModule", { value: true });
__export(__webpack_require__(8));
__export(__webpack_require__(10));


/***/ }),
/* 8 */
/***/ (function(module, exports, __webpack_require__) {

"use strict";

Object.defineProperty(exports, "__esModule", { value: true });
var helpers_1 = __webpack_require__(1);
function aggressiveTokenizerEn(text) {
    return helpers_1.trim(text.toLowerCase().split(/\W+/));
}
exports.aggressiveTokenizerEn = aggressiveTokenizerEn;


/***/ }),
/* 9 */
/***/ (function(module, exports, __webpack_require__) {

"use strict";

Object.defineProperty(exports, "__esModule", { value: true });
exports.trim = function (tokens) {
    while (tokens[tokens.length - 1] === "")
        tokens.pop();
    while (tokens[0] === "")
        tokens.shift();
    return tokens;
};


/***/ }),
/* 10 */
/***/ (function(module, exports, __webpack_require__) {

"use strict";

Object.defineProperty(exports, "__esModule", { value: true });
var helpers_1 = __webpack_require__(1);
function aggressiveTokenizerFr(text) {
    return helpers_1.trim(text.split(/[^a-z0-9äâàéèëêïîöôùüûœç]+/i));
}
exports.aggressiveTokenizerFr = aggressiveTokenizerFr;


/***/ }),
/* 11 */
/***/ (function(module, exports, __webpack_require__) {

"use strict";

Object.defineProperty(exports, "__esModule", { value: true });
function cleanData(_a) {
    var text = _a.text, tokenizer = _a.tokenizer, stemmer = _a.stemmer;
    var tokenized = tokenizer(text);
    var stemmed = stemmer ? stemmer(tokenized) : tokenized;
    return stemmed;
}
exports.cleanData = cleanData;


/***/ })
/******/ ]);
});
//# sourceMappingURL=umd.development.js.map